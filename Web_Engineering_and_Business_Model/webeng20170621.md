```


# 2017-06-21 宿題
# 下記の問にそれぞれ解答しなさい
#----------------------------------------------------------------

# インポート
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import mglearn
from IPython.display import display
%matplotlib inline

from sklearn.datasets import load_files
from sklearn.feature_extraction.text import CountVectorizer

# 準備コード
reviews = load_files("data/IMDb/")
review_text, review_label = reviews.data, reviews.target
review_text = [doc.replace(b"<br />", b" ") for doc in review_text]
review_vect = CountVectorizer(min_df=2,stop_words="english").fit(review_text)
review_bow = review_vect.transform(review_text)

# Q1 : k-最近傍法において、近傍点の数を変化させて、予測精度の変化を観察してください。
#----------------------------------------------------------------

# Q1 : Answer 

print("# Q1 : k-最近傍法において、近傍点の数を変化させて、予測精度の変化を観察してください。")
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import cross_val_score

#近傍点の数を100個の刻みで、100から1000まで変化させる
neighbors = range(100,1000,100)
for neighbor in neighbors:
    accuracy = cross_val_score(KNeighborsClassifier(n_neighbors=neighbor), review_bow, review_label, cv=5)
    #k最近傍
    print("k = %d" % neighbor)
    #各試行の精度
    print("Cross-validation accuracy: {}".format(accuracy))
    #平均精度
    print("Mean cross-validation accuracy: {:.3f}\n".format(np.mean(accuracy)))
print("\n")


# Q2 : ナイーブベイズにおいて、スムージングパラメータを変化させて、予測精度の変化を観察してください。
#----------------------------------------------------------------

# Q2 : Answer 
print("Q2 : ナイーブベイズにおいて、スムージングパラメータを変化させて、予測精度の変化を観察してください。")
from sklearn.naive_bayes import MultinomialNB

#スムージングパラメータを0.1刻みで、0.1から1.0まで変化させる
for parameter in range(1,11,1):
    parameter = parameter / 10
    accuracy = cross_val_score(MultinomialNB(alpha=parameter), review_bow, review_label, cv=5)
    print("Smoothing Parameter:{}".format(parameter))
    print("Cross-validation accuracy: {}".format(accuracy))
    print("Mean cross-validation accuracy: {:.3f}\n".format(np.mean(accuracy)))
print("\n")




# Q3 : 単語ユニグラムのtfidfベクトルを特徴量として、L1正則化を用いたロジスティック回帰による予測精度をクロスバリデーションにより出してください。
#----------------------------------------------------------------

# Q3 : Answer 
print("Q3 : 単語ユニグラムのtfidfベクトルを特徴量として、L1正則化を用いたロジスティック回帰による予測精度をクロスバリデーションにより出してください。")
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV
from sklearn.pipeline import make_pipeline

pipe = make_pipeline(TfidfVectorizer(min_df=2, stop_words="english",norm="l1", ngram_range=(1,1)), LogisticRegression())

param_grid = {'logisticregression__C': [0.01, 0.1, 1, 10]}
grid = GridSearchCV(pipe, param_grid, cv=5)
grid.fit(review_text, review_label)
print("Best cross-validation score: {:.3f}".format(grid.best_score_))
print("Best parameters:\n{}".format(grid.best_params_))
print("\n")


# Q4 : tfidfベクトルを特徴量として、単語ユニグラム、バイグラム、トライグラム、すべてを用いたロジスティック回帰による予測精度をクロスバリデーションにより出してください。
#----------------------------------------------------------------

# Q4 : Answer 
print("Q4 : tfidfベクトルを特徴量として、単語ユニグラム、バイグラム、トライグラム、すべてを用いたロジスティック回帰による予測精度をクロスバリデーションにより出してください。")
from sklearn.feature_extraction.text import TfidfVectorizer

pipe = make_pipeline(TfidfVectorizer(min_df=2, stop_words="english",norm="l1"), LogisticRegression())

param_grid = {'logisticregression__C': [0.01, 0.1, 1, 10],
              "tfidfvectorizer__ngram_range": [(1, 1), (1, 2),(1, 3)]}

grid = GridSearchCV(pipe, param_grid, cv=5)
grid.fit(review_text, review_label)
print("Best cross-validation score: {:.3f}".format(grid.best_score_))
print("Best parameters:\n{}".format(grid.best_params_))
print("\n")



# Q5 : 線形SVM、ランダムフォレスト、それぞれについて適宜最適なパラメータを探索し、それらの予測精度をロジスティック回帰のものと比較してください。
#----------------------------------------------------------------

# Q5 : Answer 
print("Q5 : 線形SVM、ランダムフォレスト、それぞれについて適宜最適なパラメータを探索し、それらの予測精度をロジスティック回帰のものと比較してください。")
from sklearn.svm import LinearSVC
print("線形SVM:")
pipe = make_pipeline(TfidfVectorizer(min_df=2, stop_words="english",norm="l1"),LinearSVC()) 
param_grid = {'linearsvc__C': [1],
                          "tfidfvectorizer__ngram_range": [(1,1),(1, 2),(1,3)]}
grid = GridSearchCV(pipe, param_grid, cv=5,)
grid.fit(review_text, review_label)
print("Best cross-validation score: {:.3f}".format(grid.best_score_))
print("Best parameters:\n{}".format(grid.best_params_))
print("\n")

from sklearn.ensemble import RandomForestClassifier
print("ランダムフォレスト:")
pipe = make_pipeline(TfidfVectorizer(min_df=2, stop_words="english",norm="l1"),RandomForestClassifier(random_state=0)) 
param_grid = {'randomforestclassifier__n_estimators': [100],
                        "tfidfvectorizer__ngram_range": [(1,1),(1, 2),(1,3)]}
grid = GridSearchCV(pipe, param_grid, cv=5,)
grid.fit(review_text, review_label)
print("Best cross-validation score: {:.3f}".format(grid.best_score_))
print("Best parameters:\n{}".format(grid.best_params_))
print("\n")

# Q6 : 学習器の組み合わせによる特徴量選択と予測のパイプラインを独自に考え、その予測精度を出してください。
#----------------------------------------------------------------

# Q6 : Answer 
print("Q6 : 学習器の組み合わせによる特徴量選択と予測のパイプラインを独自に考え、その予測精度を出してください。")
from sklearn.feature_selection import SelectFromModel

pipe = make_pipeline(TfidfVectorizer(min_df=2, stop_words="english",norm="l1"),
                     SelectFromModel(RandomForestClassifier(n_estimators=100,random_state=0),threshold=0.001),
                     LogisticRegression())
param_grid = {
                       "selectfrommodel__estimator__n_estimators": [10,50,100],
                          'logisticregression__C': [0.01, 0.1, 1, 10],
                          "tfidfvectorizer__ngram_range": [(1, 1),(1, 2),(1, 3)]}
grid = GridSearchCV(pipe, param_grid, cv=5,)
grid.fit(review_text, review_label)
print("Best cross-validation score: {:.3f}".format(grid.best_score_))
print("Best parameters:\n{}".format(grid.best_params_))
print("\n")


# Q7 : 特徴量の次元削減において、次元数を変化せて、予測精度の変化を観察してください。
#----------------------------------------------------------------

# Q7 : Answer 
print("Q7 : 特徴量の次元削減において、次元数を変化せて、予測精度の変化を観察してください。")
from sklearn.decomposition import TruncatedSVD
from sklearn.preprocessing import Normalizer

pipe = make_pipeline(TfidfVectorizer(min_df=2, stop_words="english",norm="l1"),TruncatedSVD(n_iter=7),
                                     Normalizer(copy=False),LogisticRegression())
param_grid = {
                        "truncatedsvd__n_components": [100],
                          'logisticregression__C': [0.01, 0.1, 1, 10],
                          "tfidfvectorizer__ngram_range": [(1, 1), (1, 2), (1, 3)]}
grid = GridSearchCV(pipe, param_grid, cv=5,)
grid.fit(review_text, review_label)
print("Best cross-validation score: {:.3f}".format(grid.best_score_))
print("Best parameters:\n{}".format(grid.best_params_))
print("\n")



# Q8 : 今回のデータセットにおいて、過学習を防ぎながら、予測精度をさらに向上させるにはどのような方法が考えられるか検討し、実装し評価を行ってください。
#----------------------------------------------------------------

# Q8 : Answer 


```

