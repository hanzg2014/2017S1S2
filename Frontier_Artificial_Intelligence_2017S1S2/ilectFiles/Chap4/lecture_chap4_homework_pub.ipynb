{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 第4回講義 宿題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 課題. MNISTデータセットを多層パーセプトロン(MLP)で学習せよ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 注意\n",
    "- homework関数を完成させて提出してください\n",
    "    - 訓練データはtrain_X, train_y, テストデータはtest_Xで与えられます\n",
    "    - train_Xとtrain_yをtrain_X, train_yとvalid_X, valid_yに分けるなどしてモデルを学習させてください\n",
    "    - test_Xに対して予想ラベルpred_yを作り, homework関数の戻り値としてください\\\n",
    "- pred_yのtest_yに対する精度(F値)で評価します\n",
    "- 全体の実行時間がiLect上で60分を超えないようにしてください\n",
    "- homework関数の外には何も書かないでください (必要なものは全てhomework関数に入れてください)\n",
    "- 解答提出時には Answer Cell の内容のみを提出してください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- MLPの実装にTensorflowなどのライブラリを使わないでください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### ヒント\n",
    "- 出力yはone-of-k表現\n",
    "- 最終層の活性化関数はソフトマックス関数, 誤差関数は多クラス交差エントロピー\n",
    "- 最終層のデルタは教科書参照"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "次のセルのhomework関数を完成させて提出してください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Answer Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def deriv_sigmoid(x):\n",
    "    return sigmoid(x)*(1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    exp_x = np.exp(x)\n",
    "    sum_exp_x = np.sum(exp_x)\n",
    "    return exp_x / sum_exp_x # WRITE ME!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cross_entropy(y, t):\n",
    "    return -np.sum(t*np.log(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51082545709933802"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "y = np.array([0.1,0.6,0.3])\n",
    "t = np.array([0,1,0])\n",
    "cross_entropy_error(y,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51082562376599072"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.log(y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t*np.log(y+delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "    # Forward Propagation\n",
    "    y = sigmoid(np.matmul(x, W) + b)\n",
    "    \n",
    "    # Back Propagation (Cost Function: Negative Loglikelihood)\n",
    "    cost = np.sum(-t*np.log(y)-(1-t)*np.log(1-y))\n",
    "    delta = y-t\n",
    "    \n",
    "    # Update Parameters\n",
    "    dW = np.matmul(x.T, delta)\n",
    "    db = np.matmul(np.ones(len(x)), delta)\n",
    "    W = W - eps*dW\n",
    "    b = b - eps*db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_mnist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-25927a15f7a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_mnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# validate for small dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_X_mini\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_y_mini\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_mnist' is not defined"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_y, test_y = load_mnist()\n",
    "\n",
    "# validate for small dataset\n",
    "train_X_mini = train_X[:100]\n",
    "train_y_mini = train_y[:100]\n",
    "test_X_mini = test_X[:100]\n",
    "test_y_mini = test_y[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W1 = np.random.uniform(low=-0.08, high=0.08, size=(784, 100)).astype('float32')\n",
    "b1 = np.zeros(100).astype('float32')\n",
    "W2 = np.random.uniform(low=-0.08, high=0.08, size=(100, 10)).astype('float32')\n",
    "b2 = np.zeros(10).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = train_X_mini[0][np.newaxis,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 784)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 100)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Forward Propagation Layer1\n",
    "u1 = np.matmul(x, W1) + b1\n",
    "z1 = sigmoid(u1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Forward Propagation Layer2\n",
    "u2 = np.matmul(z1, W2) + b2\n",
    "z2 = softmax(u2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.13571219,  0.07525036,  0.1068797 ,  0.12872928,  0.13106842,\n",
       "         0.07768928,  0.06244777,  0.09595294,  0.11363515,  0.07263492]], dtype=float32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = train_y_mini[0]\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.zeros(10) \n",
    "t[1]=1\n",
    "t = t[np.newaxis,:]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y = z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5869345664978027"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy_error(y,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_2 = y - t\n",
    "delta_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_1 = deriv_sigmoid(u1) * np.matmul(delta_2, W2.T) \n",
    "delta_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 100)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dW1 = np.matmul(x.T, delta_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "db1 = np.matmul(np.ones(len(x)), delta_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "eps = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0071715 , -0.00415843,  0.0120024 , -0.01090604,  0.00131286,\n",
       "       -0.01097651, -0.00804036,  0.00648411,  0.0055786 , -0.01374851,\n",
       "       -0.00986537,  0.01255385,  0.01021725,  0.01296683,  0.01996627,\n",
       "       -0.00361619,  0.01355698, -0.00693005,  0.00587283, -0.00804775,\n",
       "       -0.01092979, -0.00696836, -0.00458564, -0.01020861,  0.00472996,\n",
       "       -0.00814829,  0.0044639 ,  0.01833934,  0.00376856, -0.01689192,\n",
       "        0.01154391,  0.01267612, -0.01790225,  0.0082544 , -0.00212999,\n",
       "       -0.0157343 , -0.00283441,  0.00322465,  0.01588656,  0.00400747,\n",
       "        0.01652549, -0.00033942, -0.00633977, -0.00826913, -0.00312582,\n",
       "       -0.00995569, -0.00725526, -0.00397185, -0.01708472, -0.00741328,\n",
       "        0.00809528,  0.01150205,  0.00994808,  0.0115551 , -0.00267467,\n",
       "        0.00631692, -0.001735  ,  0.00656464,  0.01347389, -0.01004055,\n",
       "       -0.00979909,  0.02056849, -0.00343238,  0.01468042, -0.01862301,\n",
       "        0.01344985,  0.01281577, -0.01649332, -0.0062836 ,  0.00735429,\n",
       "       -0.00654036,  0.01359377,  0.0105268 ,  0.0153081 ,  0.0117807 ,\n",
       "        0.00211633, -0.00685125,  0.00232085,  0.0160172 ,  0.00488542,\n",
       "        0.00463874, -0.01508112, -0.00977181, -0.00667661,  0.00959879,\n",
       "        0.00077097,  0.00429483,  0.01446644, -0.00867957,  0.01353062,\n",
       "        0.00947925,  0.00860803, -0.00508168, -0.00368219,  0.00800378,\n",
       "        0.00118065, -0.00190688, -0.00729875,  0.01122228, -0.00619721])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W1 = W1 - eps*dW1\n",
    "b1 = b1 - eps*db1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dW2 = np.matmul(z1.T, delta_2)\n",
    "db2 = np.matmul(np.ones(len(z1)), delta_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dW2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W1 = np.random.uniform(low=-0.08, high=0.08, size=(784, 100)).astype('float32')\n",
    "b1 = np.zeros(100).astype('float32')\n",
    "W2 = np.random.uniform(low=-0.08, high=0.08, size=(100, 10)).astype('float32')\n",
    "b2 = np.zeros(10).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train(x, t, eps=0.001):\n",
    "    global W1, b1, W2, b2\n",
    "    x = x[np.newaxis,:]\n",
    "    l = np.zeros(10)\n",
    "    l[t] = 1\n",
    "    t = l\n",
    "     \n",
    "    # Forward Propagation Layer1\n",
    "    u1 = np.matmul(x, W1) + b1\n",
    "    z1 = sigmoid(u1)\n",
    "    \n",
    "    # Forward Propagation Layer2\n",
    "    u2 = np.matmul(z1, W2) + b2\n",
    "    z2 = softmax(u2)\n",
    "    \n",
    "    # Back Propagation (Cost Function: Negative Loglikelihood)\n",
    "    y = z2\n",
    "#     \n",
    "    \n",
    "    cost = cross_entropy_error(y,t)\n",
    "#     cost = np.sum(-t*np.log(y) - (1 - t)*np.log(1 - y))\n",
    "    delta_2 = y - t # Layer2 delta\n",
    "    delta_1 = deriv_sigmoid(u1) * np.matmul(delta_2, W2.T) # Layer1 delta\n",
    "#     from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
    "    # Update Parameters Layer1\n",
    "    dW1 = np.matmul(x.T, delta_1)\n",
    "    db1 = np.matmul(np.ones(len(x)), delta_1)\n",
    "    W1 = W1 - eps*dW1\n",
    "    b1 = b1 - eps*db1\n",
    "    \n",
    "    # Update Parameters Layer2\n",
    "    dW2 = np.matmul(z1.T, delta_2)\n",
    "    db2 = np.matmul(np.ones(len(z1)), delta_2)\n",
    "    W2 = W2 - eps*dW2\n",
    "    b2 = b2 - eps*db2\n",
    "    return cost\n",
    "\n",
    "def test(x, t):\n",
    "    x = x[np.newaxis,:]\n",
    "    l = np.zeros(10)\n",
    "    l[t] = 1\n",
    "    t = l\n",
    "    # Forward Propagation Layer1\n",
    "    u1 = np.matmul(x, W1) + b1\n",
    "    z1 = sigmoid(u1)\n",
    "    \n",
    "    # Forward Propagation Layer2\n",
    "    u2 = np.matmul(z1, W2) + b2\n",
    "    z2 = softmax(u2)\n",
    "    \n",
    "    y = z2   \n",
    "    # Test Cost\n",
    "    cost = -np.sum(t*log(y))\n",
    "    return cost, y.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def homework(train_X, train_y, test_X):\n",
    "    cost_array = []\n",
    "    cost_sum = []\n",
    "    for epoch in range(100):\n",
    "        # Online Learning\n",
    "        for x, y in zip(train_X, train_y):\n",
    "            x = x[np.newaxis, :]\n",
    "#             y = y[np.newaxis, :]\n",
    "            cost = train(x, y)\n",
    "            cost_sum = np.append(cost_sum, cost)\n",
    "        cost = np.sum(cost_sum)\n",
    "        cost_array = np.append(cost_array, cost)\n",
    "    pred_y = test(test_X, test_y)\n",
    "    return pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def homework(train_X, train_y, test_X):\n",
    "    eps= 1.0\n",
    "    cost = 0\n",
    "    cost_array = []\n",
    "    pred_y = []\n",
    "    length = train_X.shape[0]\n",
    "    epoch = 100\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        for x, l in zip(train_X, train_y):\n",
    "            x = x[np.newaxis, :]\n",
    "            t = np.zeros(10)\n",
    "            t[l] = 1\n",
    "    #         l = l[np.newaxis, :]\n",
    "\n",
    "            # Layer1 weights\n",
    "            W1 = np.random.uniform(low=-0.08, high=0.08, size=(784, 200)).astype('float32')\n",
    "            b1 = np.zeros(100).astype('float32')\n",
    "\n",
    "            W2 = np.random.uniform(low=-0.08, high=0.08, size=(200, 10)).astype('float32')\n",
    "            b2 = np.zeros(10).astype('float32')\n",
    "\n",
    "            u1 = np.matmul(x, W1) + b1\n",
    "            z1 = sigmoid(u1)\n",
    "\n",
    "            # Forward Propagation Layer2\n",
    "            u2 = np.matmul(z1, W2) + b2\n",
    "            z2 = softmax(u2)\n",
    "\n",
    "            # Back Propagation (Cost Function: Negative Loglikelihood)\n",
    "            y = z2   \n",
    "            cost = cross_entropy(y,t) \n",
    "            delta_2 = y - t # Layer2 delta\n",
    "    #         delta_2 = t - y # Layer2 delta\n",
    "            delta_1 = deriv_sigmoid(u1) * np.matmul(delta_2, W2.T) # Layer1 delta\n",
    "\n",
    "            # Update Parameters Layer1\n",
    "    #         from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
    "            dW1 = np.matmul(x.T, delta_1)\n",
    "            db1 = np.matmul(np.ones(len(x)), delta_1)\n",
    "            W1 = W1 - eps*dW1\n",
    "            b1 = b1 - eps*db1\n",
    "\n",
    "            # Update Parameters Layer2\n",
    "            dW2 = np.matmul(z1.T, delta_2)\n",
    "            db2 = np.matmul(np.ones(len(z1)), delta_2)\n",
    "            W2 = W2 - eps*dW2\n",
    "            b2 = b2 - eps*db2\n",
    "\n",
    "        cost_array = np.append(cost_array, cost)\n",
    "#         from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
    "        \n",
    "    for test in test_X:\n",
    "        u1 = np.matmul(x, W1) + b1\n",
    "        z1 = sigmoid(u1)\n",
    "        y = softmax(z1)\n",
    "        pred = np.argmax(y)\n",
    "#         from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
    "        pred_y = np.append(pred_y, pred)\n",
    "    plt.plot(np.arange(epoch),cost_array)\n",
    "#     from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
    "    return pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": true,
    "ilect": {
     "is_homework": true
    }
   },
   "outputs": [],
   "source": [
    "def homework(train_X, train_y, test_X):\n",
    "    # WRITE ME!\n",
    "    return pred_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- 以下のvalidate_homework関数を用いてエラーが起きないか動作確認をして下さい。\n",
    "- 提出に際して、score_homework関数で60分で実行が終わることを確認して下さい。\n",
    "- 評価は以下のscore_homework関数で行われますが、random_stateの値は変更されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Checker Cell (for student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "editable": true,
    "ilect": {
     "course_id": 4,
     "course_rank": 4,
     "is_evaluation": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def load_mnist():\n",
    "    mnist = fetch_mldata('MNIST original')\n",
    "    mnist_X, mnist_y = shuffle(mnist.data.astype('float32'),\n",
    "                               mnist.target.astype('int32'), random_state=42)\n",
    "\n",
    "    mnist_X = mnist_X / 255.0\n",
    "\n",
    "    return train_test_split(mnist_X, mnist_y,\n",
    "                test_size=0.2,\n",
    "                random_state=42)\n",
    "\n",
    "def validate_homework():\n",
    "    train_X, test_X, train_y, test_y = load_mnist()\n",
    "    \n",
    "#     train_X = train_X[np.where(train_y==1)]\n",
    "#     test_X = test_X[np.where(test_y==1)]\n",
    "#     train_y = train_y[np.where(train_y==1)]\n",
    "#     test_y = test_y[np.where(test_y==1)]\n",
    "    \n",
    "    m = 100\n",
    "    n = 100\n",
    "    # validate for small dataset\n",
    "    train_X_mini = train_X[:m]\n",
    "    train_y_mini = train_y[:m]\n",
    "    test_X_mini = test_X[:n]\n",
    "    test_y_mini = test_y[:n]\n",
    "\n",
    "#     train_X_mini = train_X[:100]\n",
    "#     train_y_mini = train_y[:100]\n",
    "#     test_X_mini = test_X[:100]\n",
    "#     test_y_mini = test_y[:100]\n",
    "\n",
    "    pred_y = homework(train_X_mini, train_y_mini, test_X_mini)\n",
    "#     from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
    "    print(f1_score(test_y_mini, pred_y, average='macro'))\n",
    "\n",
    "def score_homework():\n",
    "    train_X, test_X, train_y, test_y = load_mnist()\n",
    "    pred_y = homework(train_X, train_y, test_X)\n",
    "    print(f1_score(test_y, pred_y, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def homework(train_X, train_y, test_X):\n",
    "    cost_array = []\n",
    "    cost_sum = []\n",
    "    for epoch in range(100):\n",
    "        # Online Learning\n",
    "        for x, y in zip(train_X, train_y):\n",
    "            x = x[np.newaxis, :]\n",
    "#             y = y[np.newaxis, :]\n",
    "            cost = train(x, y)\n",
    "            cost_sum = np.append(cost_sum, cost)\n",
    "        cost = np.sum(cost_sum)\n",
    "        cost_array = np.append(cost_array, cost)\n",
    "    pred_y = test(test_X)\n",
    "    return pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(x):\n",
    "\n",
    "    # Forward Propagation Layer1\n",
    "    u1 = np.matmul(x, W1) + b1\n",
    "    z1 = sigmoid(u1)\n",
    "    \n",
    "    # Forward Propagation Layer2\n",
    "    u2 = np.matmul(z1, W2) + b2\n",
    "    z2 = softmax(u2)\n",
    "    \n",
    "    y = np.argmax(z2, axis = 1)\n",
    "    \n",
    "#     cost = -np.sum(l*log(y))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.708740067032\n"
     ]
    }
   ],
   "source": [
    "validate_homework()\n",
    "# score_homework()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Layer1 weights\n",
    "W1 = np.random.uniform(low=-0.08, high=0.08, size=(784, 100)).astype('float32')\n",
    "b1 = np.zeros(100).astype('float32')\n",
    "\n",
    "# Layer2 weights\n",
    "W2 = np.random.uniform(low=-0.08, high=0.08, size=(100,10)).astype('float32')\n",
    "b2 = np.zeros(10).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "t = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = np.zeros(10)\n",
    "l[t] = 1\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train(x, t, eps=1.0):\n",
    "    global W1, b1, W2, b2 # to access variables that defined outside of this function.\n",
    "    \n",
    "    y_tmp = np.zeros(10).reshape(1, 10)\n",
    "    y_tmp[0,t] = 1.0\n",
    "    t=y_tmp\n",
    "    # Forward Propagation Layer1\n",
    "    u1 = np.matmul(x, W1) + b1\n",
    "    z1 = sigmoid(u1)\n",
    "    \n",
    "    # Forward Propagation Layer2\n",
    "    u2 = np.matmul(z1, W2) + b2\n",
    "    z2 = softmax(u2)\n",
    "    \n",
    "    # Back Propagation (Cost Function: Negative Loglikelihood)\n",
    "#     y = z2\n",
    "#     t = (np.zeros(10)[t] = 1)\n",
    "#     t[]\n",
    "    \n",
    "    cost = cross_entropy_error(y,t)\n",
    "#     cost = np.sum(-t*np.log(y) - (1 - t)*np.log(1 - y))\n",
    "    delta_2 = y - t # Layer2 delta\n",
    "    delta_1 = deriv_sigmoid(u1) * np.matmul(delta_2, W2.T) # Layer1 delta\n",
    "#     from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
    "    # Update Parameters Layer1\n",
    "    dW1 = np.matmul(x.T, delta_1)\n",
    "    db1 = np.matmul(np.ones(len(x)), delta_1)\n",
    "    W1 = W1 - eps*dW1\n",
    "    b1 = b1 - eps*db1\n",
    "    \n",
    "    # Update Parameters Layer2\n",
    "    dW2 = np.matmul(z1.T, delta_2)\n",
    "    db2 = np.matmul(np.ones(len(z1)), delta_2)\n",
    "    W2 = W2 - eps*dW2\n",
    "    b2 = b2 - eps*db2\n",
    "\n",
    "    return cost\n",
    "\n",
    "def test(x, t):\n",
    "\n",
    "    # Forward Propagation Layer1\n",
    "    u1 = np.matmul(x, W1) + b1\n",
    "    z1 = sigmoid(u1)\n",
    "    \n",
    "    # Forward Propagation Layer2\n",
    "    u2 = np.matmul(z1, W2) + b2\n",
    "    z2 = softmax(u2)\n",
    "    \n",
    "    y = argmax(z2, axis = 1)\n",
    "    \n",
    "#     cost = -np.sum(l*log(y))\n",
    "    return y\n",
    "#     return cost, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(x, t, eps=0.2):\n",
    "    global W1, b1, W2, b2  # to access variables that defined outside of this function.\n",
    "\n",
    "    y_tmp = np.zeros(10).reshape(1, 10)\n",
    "    y_tmp[0,t] = 1.0\n",
    "    train_y=y_tmp\n",
    "    # Forward Propagation Layer1\n",
    "    u1 = np.matmul(x, W1) + b1\n",
    "    z1 = sigmoid(u1)\n",
    "\n",
    "    # Forward Propagation Layer2\n",
    "    u2 = np.matmul(z1, W2) + b2\n",
    "    z2 = softmax(u2)\n",
    "\n",
    "    # Back Propagation (Cost Function: Negative Loglikelihood)\n",
    "    y = z2\n",
    "    # cost = np.sum(-t * np.log(y) - (1 - t) * np.log(1 - y))\n",
    "    cost = -np.log(y[0,t])\n",
    "    \n",
    "    delta_2 = (y-train_y)\n",
    "    delta_1 = deriv_sigmoid(u1) * np.matmul(delta_2, W2.T)  # Layer1 delta\n",
    "\n",
    "    # Update Parameters Layer1\n",
    "    dW1 = np.matmul(x.T, delta_1)\n",
    "    db1 = np.matmul(np.ones(len(x)), delta_1)\n",
    "    W1 = W1 - eps * dW1\n",
    "    b1 = b1 - eps * db1\n",
    "\n",
    "    # Update Parameters Layer2\n",
    "    dW2 = np.matmul(z1.T, delta_2)\n",
    "    db2 = np.matmul(np.ones(len(z1)), delta_2)\n",
    "    W2 = W2 - eps * dW2\n",
    "    b2 = b2 - eps * db2\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-40746fecdd0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Online Learning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_X' is not defined"
     ]
    }
   ],
   "source": [
    "# Epoch\n",
    "cost_array = []\n",
    "cost_sum = []\n",
    "for epoch in range(100):\n",
    "    # Online Learning\n",
    "    for x, y in zip(train_X, train_y):\n",
    "        x = x[np.newaxis, :]\n",
    "        y = y[np.newaxis, :]\n",
    "        cost = train(x, y)\n",
    "        cost_sum = np.append(cost_sum, cost)\n",
    "    pred_y = test(test_X, test_y)\n",
    "    cost = np.sum(cost_sum)\n",
    "    cost_array = np.append(cost_array, cost)\n",
    "\n",
    "print(cost)\n",
    "print(pred_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
